{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "looking-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../../src')\n",
    "\n",
    "# others shit\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# my shit\n",
    "from lib.stonk_jar import StonkJar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "considered-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'AAPL'\n",
    "jar = StonkJar(ticker)\n",
    "historical_pickle_name = \"{0}.technical.1.historical.df.pkl\".format(ticker)\n",
    "data = jar.read_pickle_dataframe(historical_pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "declared-integer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v</th>\n",
       "      <th>e_a</th>\n",
       "      <th>e_e</th>\n",
       "      <th>r_ss</th>\n",
       "      <th>r_s</th>\n",
       "      <th>r_h</th>\n",
       "      <th>r_b</th>\n",
       "      <th>r_sb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.860305e+06</td>\n",
       "      <td>3.860305e+06</td>\n",
       "      <td>3.860305e+06</td>\n",
       "      <td>3.860305e+06</td>\n",
       "      <td>3.860305e+06</td>\n",
       "      <td>3.860305e+06</td>\n",
       "      <td>3.860305e+06</td>\n",
       "      <td>3.860305e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.000387e+01</td>\n",
       "      <td>1.680000e+00</td>\n",
       "      <td>1.555857e+00</td>\n",
       "      <td>1.537892e-02</td>\n",
       "      <td>1.537892e-02</td>\n",
       "      <td>1.784524e-01</td>\n",
       "      <td>5.083847e-01</td>\n",
       "      <td>2.824051e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.857487e+01</td>\n",
       "      <td>1.376677e-14</td>\n",
       "      <td>1.421086e-14</td>\n",
       "      <td>1.149616e-02</td>\n",
       "      <td>1.149616e-02</td>\n",
       "      <td>1.842182e-02</td>\n",
       "      <td>3.311151e-02</td>\n",
       "      <td>6.699199e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.680000e+00</td>\n",
       "      <td>1.555857e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.582734e-01</td>\n",
       "      <td>4.520548e-01</td>\n",
       "      <td>2.773973e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>1.680000e+00</td>\n",
       "      <td>1.555857e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.582734e-01</td>\n",
       "      <td>4.760274e-01</td>\n",
       "      <td>2.773973e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>1.680000e+00</td>\n",
       "      <td>1.555857e+00</td>\n",
       "      <td>2.397260e-02</td>\n",
       "      <td>2.397260e-02</td>\n",
       "      <td>1.746575e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>2.773973e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.500000e+01</td>\n",
       "      <td>1.680000e+00</td>\n",
       "      <td>1.555857e+00</td>\n",
       "      <td>2.397260e-02</td>\n",
       "      <td>2.397260e-02</td>\n",
       "      <td>1.986301e-01</td>\n",
       "      <td>5.503597e-01</td>\n",
       "      <td>2.913669e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>1.680000e+00</td>\n",
       "      <td>1.555857e+00</td>\n",
       "      <td>2.397260e-02</td>\n",
       "      <td>2.397260e-02</td>\n",
       "      <td>2.226027e-01</td>\n",
       "      <td>5.503597e-01</td>\n",
       "      <td>2.913669e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  v           e_a           e_e          r_ss           r_s  \\\n",
       "count  3.860305e+06  3.860305e+06  3.860305e+06  3.860305e+06  3.860305e+06   \n",
       "mean   5.000387e+01  1.680000e+00  1.555857e+00  1.537892e-02  1.537892e-02   \n",
       "std    2.857487e+01  1.376677e-14  1.421086e-14  1.149616e-02  1.149616e-02   \n",
       "min    1.000000e+00  1.680000e+00  1.555857e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.500000e+01  1.680000e+00  1.555857e+00  0.000000e+00  0.000000e+00   \n",
       "50%    5.000000e+01  1.680000e+00  1.555857e+00  2.397260e-02  2.397260e-02   \n",
       "75%    7.500000e+01  1.680000e+00  1.555857e+00  2.397260e-02  2.397260e-02   \n",
       "max    9.900000e+01  1.680000e+00  1.555857e+00  2.397260e-02  2.397260e-02   \n",
       "\n",
       "                r_h           r_b          r_sb  \n",
       "count  3.860305e+06  3.860305e+06  3.860305e+06  \n",
       "mean   1.784524e-01  5.083847e-01  2.824051e-01  \n",
       "std    1.842182e-02  3.311151e-02  6.699199e-03  \n",
       "min    1.582734e-01  4.520548e-01  2.773973e-01  \n",
       "25%    1.582734e-01  4.760274e-01  2.773973e-01  \n",
       "50%    1.746575e-01  5.000000e-01  2.773973e-01  \n",
       "75%    1.986301e-01  5.503597e-01  2.913669e-01  \n",
       "max    2.226027e-01  5.503597e-01  2.913669e-01  "
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-crack",
   "metadata": {},
   "source": [
    "LTSM/Keras code below jacked shamelessly from https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "agricultural-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "\n",
    "n_features = 5\n",
    "\n",
    "# number of samples to use to train in each round\n",
    "# samples in this case are hourly tickers, so this is a 8hr trading day\n",
    "n_samples = 8\n",
    "\n",
    "# output 1 prediction\n",
    "n_outputs = 1\n",
    "\n",
    "# 5 days of trading data at a time\n",
    "batch_size = n_samples * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "frank-evanescence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       ts                           o  \\\n",
      "ts                                                      \n",
      "0     2020-11-01 05:00:00                     122.631   \n",
      "1     2020-11-01 05:01:00                  122.385738   \n",
      "2     2020-11-01 05:02:00                  122.140967   \n",
      "3     2020-11-01 05:03:00                  122.690601   \n",
      "4     2020-11-01 05:04:00                  123.242709   \n",
      "...                   ...                         ...   \n",
      "38692 2021-02-28 02:52:00  120734955111893189001216.0   \n",
      "38693 2021-02-28 02:53:00  121278262409896724004864.0   \n",
      "38694 2021-02-28 02:54:00  121824014590741237989376.0   \n",
      "38695 2021-02-28 02:55:00  121580366561559760076800.0   \n",
      "38696 2021-02-28 02:56:00  122127478211086762639360.0   \n",
      "\n",
      "                                l                           h  \\\n",
      "ts                                                              \n",
      "0                             123                    122.8155   \n",
      "1                         122.754                  122.569869   \n",
      "2                      122.508492                  122.790262   \n",
      "3                       123.05978                  123.342818   \n",
      "4                      123.613549                   123.89786   \n",
      "...                           ...                         ...   \n",
      "38692  121098249861477628379136.0  121376775836159023513600.0   \n",
      "38693  121643191985854279057408.0  121922971327421736812544.0   \n",
      "38694  122190586349790611636224.0  122007300470265924812800.0   \n",
      "38695  121946205177091029204992.0  122226681448998337773568.0   \n",
      "38696  122494963100387932897280.0  122776701515518818910208.0   \n",
      "\n",
      "                                c   v  \n",
      "ts                                     \n",
      "0                         123.492  82  \n",
      "1                      123.245016  15  \n",
      "2                      122.998526  22  \n",
      "3                      123.552019  41  \n",
      "4                      124.108003  18  \n",
      "...                           ...  ..  \n",
      "38692  121582642860923547549696.0  59  \n",
      "38693  122129764753797696978944.0  51  \n",
      "38694  122679348695189776498688.0   1  \n",
      "38695  122433989997799399227392.0  95  \n",
      "38696  122984942952789487648768.0   7  \n",
      "\n",
      "[3860305 rows x 6 columns]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 1 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-378-3f4aa56d06f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# wtf is the 4 about? why 4?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;31m# ensure all data is float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 4"
     ]
    }
   ],
   "source": [
    "# prepare data for lstm\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "data.drop(data.columns[[6, 7, 8, 9, 10, 11, 12]], axis=1, inplace=True)\n",
    "data.index.name = 'ts'\n",
    "print(data)\n",
    "values = data.values[:, 1:(n_features)]\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "# wtf is the 4 about? why 4?\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_samples, n_outputs)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "training_pct = 0.75\n",
    "n_training = int(len(values) * 0.75)\n",
    "train = values[:n_training, :]\n",
    "test = values[n_training:, :]\n",
    "# split into input and outputs\n",
    "n_obs = n_samples * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_samples, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_samples, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-portland",
   "metadata": {},
   "source": [
    ">We will define the LSTM with 50 neurons in the first hidden layer and 1 neuron in the output layer for predicting pollution. The input shape will be 1 time step with 8 features.\n",
    ">\n",
    ">We will use the Mean Absolute Error (MAE) loss function and the efficient Adam version of stochastic gradient descent.\n",
    ">\n",
    ">The model will be fit for 50 training epochs with a batch size of 72. Remember that the internal state of the LSTM in Keras is reset at the end of each batch, so an internal state that is a function of a number of days may be helpful (try testing this).\n",
    ">\n",
    ">Finally, we keep track of both the training and test loss during training by setting the validation_data argument in the fit() function. At the end of the run both the training and test loss are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(n_outputs))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=batch_size, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X_pred = test_X.reshape((test_X.shape[0], n_samples*n_features))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X_pred[:, -(n_features-1):]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y_pred = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y_pred, test_X_pred[:, -(n_features-1):]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the last \n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
